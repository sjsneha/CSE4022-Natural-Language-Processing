{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31564073",
   "metadata": {},
   "source": [
    "# NLTK Hands On Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5005d",
   "metadata": {},
   "source": [
    "# Details:22-12-2022\n",
    "# Topic: Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af078eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cdc3781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 6, 'of': 5, 'and': 5, 'language': 3, 'is': 2, 'computer': 2, 'computers': 2, 'in': 2, 'to': 2, 'The': 2, ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency Distribution of Words\n",
    "txt1 = \"Natural language processing (NLP) is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The goal is a computer capable of \\\"understanding\\\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\n",
    "fd = nltk.FreqDist(txt1.split())\n",
    "fd\n",
    "# print(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ddc5872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'with': 1, 'goal': 1, 'then': 1, 'well': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "cfd = ConditionalFreqDist((len(word),word) for word in txt1.split())\n",
    "cfd[4] # gives you 4 words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e593dc6a",
   "metadata": {},
   "source": [
    "## HW : To determine Frequency Distribution and Conditional Frequency Distribution of any one of the Presential inaugural address (nouns-> business not adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ac8602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 12, 'of': 12, 'a': 9, 'to': 8, 'our': 8, 'that': 6, 'us': 4, 'we': 3, 'is': 3, 'or': 3, ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2 = \"Each time we gather to inaugurate a President we bear witness to the enduring strength of our Constitution.  We affirm the promise of our democracy.  We recall that what binds this nation together is not the colors of our skin or the tenets of our faith or the origins of our names.  What makes us exceptional -- what makes us American -- is our allegiance to an idea articulated in a declaration made more than two centuries ago:\\“We hold these truths to be self-evident, that all men are created equal; that they are endowed by their Creator with certain unalienable rights; that among these are life, liberty, and the pursuit of happiness.\\”Today we continue a never-ending journey to bridge the meaning of those words with the realities of our time.  For history tells us that while these truths may be self-evident, they’ve never been self-executing; that while freedom is a gift from God, it must be secured by His people here on Earth.  (Applause.)  The patriots of 1776 did not fight to replace the tyranny of a king with the privileges of a few or the rule of a mob.  They gave to us a republic, a government of, and by, and for the people, entrusting each generation to keep safe our founding creed.  \"\n",
    "fd = nltk.FreqDist(txt2.split())\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695faf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'that': 6, 'with': 3, 'what': 2, 'Each': 1, 'time': 1, 'bear': 1, 'this': 1, 'skin': 1, 'What': 1, 'idea': 1, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = ConditionalFreqDist((len(word),word) for word in txt2.split())\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c3de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=eb24f0d31f73a113acc7ec166144ca9d59bc7d06e0321a00a9a8621e366fe868\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\7d\\74\\cf\\08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install jieba\n",
    "#since CJK(Chinese Jpanese Korean) doesn't have any word boundary so jieba will give word boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f95d4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\Asus\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.390 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《 嘉定 屠城 紀 略 》 影印 影印本 印本 重 複\n"
     ]
    }
   ],
   "source": [
    "# Task 5: CHINESE SEGMENTATION USING JIEBA\n",
    "import jieba\n",
    "seg = jieba.cut(\"《嘉定屠城紀略》影印本重複\", cut_all = True)\n",
    "print(\" \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "445d8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', ',', 'an', 'expert', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "# BASIC TEXT PROCESSING PIPELINE\n",
    "import nltk\n",
    "sent = \"Become an expert in NLP\"\n",
    "words = nltk.word_tokenize(sent) # Splitting of words (same as splitting)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd76e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'premise', 'of', 'symbolic', 'NLP', 'is', 'well-summarized', 'by', 'John', 'Searle', \"'s\", 'Chinese', 'room', 'experiment', ':', 'Given', 'a', 'collection', 'of', 'rules', '(', 'e.g.', ',', 'a', 'Chinese', 'phrasebook', ',', 'with', 'questions', 'and', 'matching', 'answers', ')', ',', 'the', 'computer', 'emulates', 'natural', 'language', 'understanding', '(', 'or', 'other', 'NLP', 'tasks', ')', 'by', 'applying', 'those', 'rules', 'to', 'the', 'data', 'it', 'confronts', '.']\n",
      "\n",
      "[('The', 'DT'), ('premise', 'NN'), ('of', 'IN'), ('symbolic', 'JJ'), ('NLP', 'NNP'), ('is', 'VBZ'), ('well-summarized', 'JJ'), ('by', 'IN'), ('John', 'NNP'), ('Searle', 'NNP'), (\"'s\", 'POS'), ('Chinese', 'JJ'), ('room', 'NN'), ('experiment', 'NN'), (':', ':'), ('Given', 'VBN'), ('a', 'DT'), ('collection', 'NN'), ('of', 'IN'), ('rules', 'NNS'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('a', 'DT'), ('Chinese', 'JJ'), ('phrasebook', 'NN'), (',', ','), ('with', 'IN'), ('questions', 'NNS'), ('and', 'CC'), ('matching', 'VBG'), ('answers', 'NNS'), (')', ')'), (',', ','), ('the', 'DT'), ('computer', 'NN'), ('emulates', 'VBZ'), ('natural', 'JJ'), ('language', 'NN'), ('understanding', 'NN'), ('(', '('), ('or', 'CC'), ('other', 'JJ'), ('NLP', 'NNP'), ('tasks', 'NNS'), (')', ')'), ('by', 'IN'), ('applying', 'VBG'), ('those', 'DT'), ('rules', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('data', 'NNS'), ('it', 'PRP'), ('confronts', 'VBZ'), ('.', '.')]\n",
      "\n",
      "\n",
      "['1950s', ':', 'The', 'Georgetown', 'experiment', 'in', '1954', 'involved', 'fully', 'automatic', 'translation', 'of', 'more', 'than', 'sixty', 'Russian', 'sentences', 'into', 'English', '.']\n",
      "\n",
      "[('1950s', 'NNS'), (':', ':'), ('The', 'DT'), ('Georgetown', 'NNP'), ('experiment', 'NN'), ('in', 'IN'), ('1954', 'CD'), ('involved', 'JJ'), ('fully', 'RB'), ('automatic', 'JJ'), ('translation', 'NN'), ('of', 'IN'), ('more', 'JJR'), ('than', 'IN'), ('sixty', 'NN'), ('Russian', 'JJ'), ('sentences', 'NNS'), ('into', 'IN'), ('English', 'NNP'), ('.', '.')]\n",
      "\n",
      "\n",
      "['The', 'authors', 'claimed', 'that', 'within', 'three', 'or', 'five', 'years', ',', 'machine', 'translation', 'would', 'be', 'a', 'solved', 'problem', '.']\n",
      "\n",
      "[('The', 'DT'), ('authors', 'NNS'), ('claimed', 'VBD'), ('that', 'IN'), ('within', 'IN'), ('three', 'CD'), ('or', 'CC'), ('five', 'CD'), ('years', 'NNS'), (',', ','), ('machine', 'NN'), ('translation', 'NN'), ('would', 'MD'), ('be', 'VB'), ('a', 'DT'), ('solved', 'JJ'), ('problem', 'NN'), ('.', '.')]\n",
      "\n",
      "\n",
      "['[', '2', ']', 'However', ',', 'real', 'progress', 'was', 'much', 'slower', ',', 'and', 'after', 'the', 'ALPAC', 'report', 'in', '1966', ',', 'which', 'found', 'that', 'ten-year-long', 'research', 'had', 'failed', 'to', 'fulfill', 'the', 'expectations', ',', 'funding', 'for', 'machine', 'translation', 'was', 'dramatically', 'reduced', '.']\n",
      "\n",
      "[('[', 'RB'), ('2', 'CD'), (']', 'JJ'), ('However', 'RB'), (',', ','), ('real', 'JJ'), ('progress', 'NN'), ('was', 'VBD'), ('much', 'RB'), ('slower', 'JJR'), (',', ','), ('and', 'CC'), ('after', 'IN'), ('the', 'DT'), ('ALPAC', 'NNP'), ('report', 'NN'), ('in', 'IN'), ('1966', 'CD'), (',', ','), ('which', 'WDT'), ('found', 'VBD'), ('that', 'IN'), ('ten-year-long', 'JJ'), ('research', 'NN'), ('had', 'VBD'), ('failed', 'VBN'), ('to', 'TO'), ('fulfill', 'VB'), ('the', 'DT'), ('expectations', 'NNS'), (',', ','), ('funding', 'VBG'), ('for', 'IN'), ('machine', 'NN'), ('translation', 'NN'), ('was', 'VBD'), ('dramatically', 'RB'), ('reduced', 'VBN'), ('.', '.')]\n",
      "\n",
      "\n",
      "['Little', 'further', 'research', 'in', 'machine', 'translation', 'was', 'conducted', 'until', 'the', 'late', '1980s', 'when', 'the', 'first', 'statistical', 'machine', 'translation', 'systems', 'were', 'developed', '.']\n",
      "\n",
      "[('Little', 'JJ'), ('further', 'JJ'), ('research', 'NN'), ('in', 'IN'), ('machine', 'NN'), ('translation', 'NN'), ('was', 'VBD'), ('conducted', 'VBN'), ('until', 'IN'), ('the', 'DT'), ('late', 'JJ'), ('1980s', 'NNS'), ('when', 'WRB'), ('the', 'DT'), ('first', 'JJ'), ('statistical', 'JJ'), ('machine', 'NN'), ('translation', 'NN'), ('systems', 'NNS'), ('were', 'VBD'), ('developed', 'VBN'), ('.', '.')]\n",
      "\n",
      "\n",
      "['1960s', ':', 'Some', 'notably', 'successful', 'natural', 'language', 'processing', 'systems', 'developed', 'in', 'the', '1960s', 'were', 'SHRDLU', ',', 'a', 'natural', 'language', 'system', 'working', 'in', 'restricted', '``', 'blocks', 'worlds', \"''\", 'with', 'restricted', 'vocabularies', ',', 'and', 'ELIZA', ',', 'a', 'simulation', 'of', 'a', 'Rogerian', 'psychotherapist', ',', 'written', 'by', 'Joseph', 'Weizenbaum', 'between', '1964', 'and', '1966', '.']\n",
      "\n",
      "[('1960s', 'NNS'), (':', ':'), ('Some', 'DT'), ('notably', 'RB'), ('successful', 'JJ'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'VBG'), ('systems', 'NNS'), ('developed', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('1960s', 'NNS'), ('were', 'VBD'), ('SHRDLU', 'NNP'), (',', ','), ('a', 'DT'), ('natural', 'JJ'), ('language', 'NN'), ('system', 'NN'), ('working', 'VBG'), ('in', 'IN'), ('restricted', 'VBN'), ('``', '``'), ('blocks', 'NNS'), ('worlds', 'NNS'), (\"''\", \"''\"), ('with', 'IN'), ('restricted', 'JJ'), ('vocabularies', 'NNS'), (',', ','), ('and', 'CC'), ('ELIZA', 'NNP'), (',', ','), ('a', 'DT'), ('simulation', 'NN'), ('of', 'IN'), ('a', 'DT'), ('Rogerian', 'JJ'), ('psychotherapist', 'NN'), (',', ','), ('written', 'VBN'), ('by', 'IN'), ('Joseph', 'NNP'), ('Weizenbaum', 'NNP'), ('between', 'IN'), ('1964', 'CD'), ('and', 'CC'), ('1966', 'CD'), ('.', '.')]\n",
      "\n",
      "\n",
      "['Using', 'almost', 'no', 'information', 'about', 'human', 'thought', 'or', 'emotion', ',', 'ELIZA', 'sometimes', 'provided', 'a', 'startlingly', 'human-like', 'interaction', '.']\n",
      "\n",
      "[('Using', 'VBG'), ('almost', 'RB'), ('no', 'DT'), ('information', 'NN'), ('about', 'IN'), ('human', 'JJ'), ('thought', 'NN'), ('or', 'CC'), ('emotion', 'NN'), (',', ','), ('ELIZA', 'NNP'), ('sometimes', 'RB'), ('provided', 'VBD'), ('a', 'DT'), ('startlingly', 'RB'), ('human-like', 'JJ'), ('interaction', 'NN'), ('.', '.')]\n",
      "\n",
      "\n",
      "['When', 'the', '``', 'patient', \"''\", 'exceeded', 'the', 'very', 'small', 'knowledge', 'base', ',', 'ELIZA', 'might', 'provide', 'a', 'generic', 'response', ',', 'for', 'example', ',', 'responding', 'to', '``', 'My', 'head', 'hurts', \"''\", 'with', '``', 'Why', 'do', 'you', 'say', 'your', 'head', 'hurts', '?']\n",
      "\n",
      "[('When', 'WRB'), ('the', 'DT'), ('``', '``'), ('patient', 'NN'), (\"''\", \"''\"), ('exceeded', 'VBD'), ('the', 'DT'), ('very', 'RB'), ('small', 'JJ'), ('knowledge', 'NN'), ('base', 'NN'), (',', ','), ('ELIZA', 'NNP'), ('might', 'MD'), ('provide', 'VB'), ('a', 'DT'), ('generic', 'JJ'), ('response', 'NN'), (',', ','), ('for', 'IN'), ('example', 'NN'), (',', ','), ('responding', 'VBG'), ('to', 'TO'), ('``', '``'), ('My', 'PRP$'), ('head', 'NN'), ('hurts', 'NNS'), (\"''\", \"''\"), ('with', 'IN'), ('``', '``'), ('Why', 'WRB'), ('do', 'VBP'), ('you', 'PRP'), ('say', 'VB'), ('your', 'PRP$'), ('head', 'NN'), ('hurts', 'NNS'), ('?', '.')]\n",
      "\n",
      "\n",
      "['``', '.']\n",
      "\n",
      "[('``', '``'), ('.', '.')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\"\"\"The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n",
    "1950s: The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s when the first statistical machine translation systems were developed.\n",
    "1960s: Some notably successful natural language processing systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966. Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\"\"\"]\n",
    "\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text) # tokenize sentence\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence) # tokenize words in each sentence\n",
    "        print(words)\n",
    "        print()\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        print(tagged)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5474b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
